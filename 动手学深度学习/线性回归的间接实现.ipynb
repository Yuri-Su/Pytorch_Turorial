{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch.utils.data as Data\r\n",
    "import torch\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "num_inputs = 2\r\n",
    "num_examples = 1000\r\n",
    "true_w = [2, -3.4]\r\n",
    "true_b = 4.2\r\n",
    "features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float)\r\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\r\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)\r\n",
    "\r\n",
    "batch_size = 32\r\n",
    "\r\n",
    "dataset = Data.TensorDataset(features,labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def data_iter(batch_size, features, labels):\r\n",
    "    num_examples = len(features)\r\n",
    "    indices = list(range(num_examples))\r\n",
    "    random.shuffle(indices)\r\n",
    "    for i in range(0, num_examples, batch_size):\r\n",
    "        j = torch.LongTensor(indices[i:min(i + batch_size, num_examples)])\r\n",
    "        yield features.index_select(0, j), labels.index_select(\r\n",
    "            0, j)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data_iter = Data.DataLoader(dataset, batch_size, shuffle=True)\r\n",
    "\r\n",
    "for X, y in data_iter:\r\n",
    "    print(X, y)\r\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.4302, -0.7976],\n",
      "        [-1.3555,  0.1909],\n",
      "        [-0.4244, -0.1911],\n",
      "        [-0.5975,  0.1618],\n",
      "        [ 0.3236, -0.1173],\n",
      "        [ 0.1115, -1.2463],\n",
      "        [ 1.3928, -1.2630],\n",
      "        [ 0.0033, -2.4750],\n",
      "        [ 1.7536,  0.8324],\n",
      "        [ 0.0762,  1.7674],\n",
      "        [-0.9593,  1.0579],\n",
      "        [-0.7738, -0.0482],\n",
      "        [-1.2796,  0.2263],\n",
      "        [-1.3886,  0.6845],\n",
      "        [-0.9094,  0.5778],\n",
      "        [-2.0111,  0.2090],\n",
      "        [-0.2983, -0.0621],\n",
      "        [-1.0997, -0.7513],\n",
      "        [ 0.4069,  0.3781],\n",
      "        [-0.0988, -1.4225],\n",
      "        [-1.3866,  0.0036],\n",
      "        [ 1.1796,  2.1882],\n",
      "        [-1.8575, -0.5420],\n",
      "        [-1.8676, -0.9497],\n",
      "        [ 0.8633, -0.9826],\n",
      "        [-1.5069, -1.2985],\n",
      "        [ 0.6443,  0.9282],\n",
      "        [ 0.1459, -0.2731],\n",
      "        [ 0.0057, -0.0818],\n",
      "        [ 1.5517,  0.4084],\n",
      "        [-1.2332,  0.8785],\n",
      "        [ 1.6544,  0.1324]]) tensor([ 9.7617,  0.8434,  3.9912,  2.4545,  5.2487,  8.6764, 11.2702, 12.6339,\n",
      "         4.8729, -1.6367, -1.3224,  2.8285,  0.8791, -0.9126,  0.4229, -0.5322,\n",
      "         3.8013,  4.5623,  3.7471,  8.8307,  1.4234, -0.8974,  2.3297,  3.7056,\n",
      "         9.2734,  5.6040,  2.3344,  5.4323,  4.5128,  5.9117, -1.2658,  7.0782])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import torch.nn as nn\r\n",
    "\r\n",
    "class LinearNet(nn.Module):\r\n",
    "    def __init__(self, n_feature):\r\n",
    "        super(LinearNet, self).__init__()\r\n",
    "        self.linear = nn.Linear(n_feature, 1)\r\n",
    "    # forward 定义前向传播\r\n",
    "    def forward(self, x):\r\n",
    "        y = self.linear(x)\r\n",
    "        return y\r\n",
    "net = LinearNet(num_inputs)\r\n",
    "print(net) # 使用print可以打印出网络的结构"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LinearNet(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "for param in net.parameters():\r\n",
    "    print(param)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5767, -0.1550]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2703], requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import torch.optim as optim\r\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.03)\r\n",
    "print(optimizer)\r\n",
    "loss = nn.MSELoss()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "num_epochs = 3\r\n",
    "for epoch in range(1, num_epochs + 1):\r\n",
    "    for X, y in data_iter:\r\n",
    "        output = net(X)\r\n",
    "        l = loss(output, y.view(-1, 1))\r\n",
    "        optimizer.zero_grad() # 梯度清零，等价于net.zero_grad()\r\n",
    "        l.backward()\r\n",
    "        optimizer.step()\r\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1, loss: 0.327935\n",
      "epoch 2, loss: 0.003105\n",
      "epoch 3, loss: 0.000414\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "3860d6e0d0be45158f67b7497cd86fa5fc648422f0e508ab3756a6a3a2719315"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}